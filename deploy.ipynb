{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"d74ca76c-0758-4302-8894-12939776ca14\" # The ID of the Azure Subscription\n",
    "resource_group = \"fastai-practise\" # Name of a logical resource group\n",
    "workspace_name = \"Azure_projects\" # The name of the workspace to look for or to create\n",
    "workspace_region = 'northcentralus' # Location of the workspace\n",
    "experiment_name = 'cars-classifier'\n",
    "score_script = 'score_and_track.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Deploying AppInsights with name azureproinsights03ddb98d.\nDeployed AppInsights with name azureproinsights03ddb98d. Took 2.16 seconds.\nDeploying KeyVault with name azureprokeyvault0276f48d.\nDeploying StorageAccount with name azureprostoragecf2e28677.\nDeployed KeyVault with name azureprokeyvault0276f48d. Took 17.47 seconds.\nDeployed StorageAccount with name azureprostoragecf2e28677. Took 18.96 seconds.\nDeploying Workspace with name Azure_projects.\nDeployed Workspace with name Azure_projects. Took 18.2 seconds.\n"
    }
   ],
   "source": [
    "ws = Workspace.create(name=workspace_name,\n",
    "               subscription_id=subscription_id,\n",
    "               resource_group=resource_group,\n",
    "               create_resource_group=True,\n",
    "               location=workspace_region,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = Workspace.get(name=\"Azure_projects\", subscription_id='d74ca76c-0758-4302-8894-12939776ca14', resource_group='fastai-practise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Registering model cars-classifier\n"
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path=\"export.pkl\",\n",
    "                          model_name=\"cars-classifier\",\n",
    "                          tags={'data': 'cars', 'method':'transfer learning','framework':'pytorch'},\n",
    "                          description='Image classficiation service BMW vs Jagaur vs Mclauren',\n",
    "                          workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "# Conda environment specification. The dependencies defined in this file will\n# be automatically provisioned for runs with userManagedDependencies=False.\n\n# Details about the Conda environment file format:\n# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n\nname: project_environment\ndependencies:\n  # The python interpreter version.\n  # Currently Azure ML only supports 3.5.2 and later.\n- python=3.6.2\n\n- pip:\n  - azureml-defaults\n  - fastai==1.0.60\n  - pillow==5.4.1\n  - torch\n  - torchvision>=0.5.0\nchannels:\n- conda-forge\n\n"
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=['azureml-defaults', 'fastai==1.0.60','pillow==5.4.1',\n",
    "                                               'torch', 'torchvision>=0.5.0'])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "    \n",
    "print(myenv.serialize_to_string())\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score_and_track.py\",\n",
    "                                   environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "\n",
    "service_name = 'cars'\n",
    "\n",
    "# Remove any existing service under the same name.\n",
    "try:\n",
    "   Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "   pass\n",
    "    \n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=2, \n",
    "                                               memory_gb=4, \n",
    "                                               tags={'data': 'cars',  'method':'transfer learning', 'framework':'pytorch'},\n",
    "                                               description='Image classficiation service BMW vs Jagaur vs Mclauren')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Running.............................................................................................................................................\nSucceeded\nACI service creation operation finished, operation \"Succeeded\"\nHealthy\n"
    }
   ],
   "source": [
    "service = Model.deploy(workspace=ws, \n",
    "                           name=service_name, \n",
    "                           models=[model], \n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'/bin/bash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n2020-03-12T22:52:55,600960588+00:00 - gunicorn/run \\n2020-03-12T22:52:55,602251294+00:00 - iot-server/run \\n2020-03-12T22:52:55,602442995+00:00 - rsyslog/run \\n2020-03-12T22:52:55,603471701+00:00 - nginx/run \\n/bin/bash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/usr/sbin/nginx: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\nbash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by bash)\\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n/bin/bash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n2020-03-12T22:52:55,681310904+00:00 - iot-server/finish 1 0\\n2020-03-12T22:52:55,682734712+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (14)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 42\\nInitialized PySpark session.\\ngenerated new fontManager\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user\\'s init function\\n2020-03-12 22:52:58,617 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\\n\\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \"error\": {\\n        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\\n    }\\n}, switching offline: False\\n2020-03-12 22:52:58,617 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\\n2020-03-12 22:52:58,617 | azureml.core.model | DEBUG | version is None. Latest version is 1\\n2020-03-12 22:52:58,617 | azureml.core.model | DEBUG | Found model path at azureml-models/cars-classifier/1/export.pkl\\nUsers\\'s init has completed successfully\\nScoring timeout is found from os.environ: 60000 ms\\n'"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "http://e411f54b-e480-44d9-ba36-5b29b0ace6fe.westus.azurecontainer.io/score\n"
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "{\"category\": \"Jagaur\", \"confidence\": 0.00086649798322469}\n"
    }
   ],
   "source": [
    "import json, requests\n",
    "import os, base64\n",
    "import urllib\n",
    "\n",
    "#from PIL import Image\n",
    "\n",
    "def preprocess(image):\n",
    "    \n",
    "    with open(image,mode='rb') as file:\n",
    "        img = file.read()\n",
    "\n",
    "    data = str(base64.b64encode(img), encoding='utf-8')  \n",
    "    input_data = json.dumps({'data': data})\n",
    "    return input_data\n",
    "\n",
    "\n",
    "input_data = preprocess('test2.jpg')\n",
    "\n",
    "result = service.run(input_data=input_data)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python (Cars_Classfier)",
   "language": "python",
   "name": "cars_classfier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5-final"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}