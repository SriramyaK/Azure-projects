{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_id = \"d74ca76c-0758-4302-8894-12939776ca14\" # The ID of the Azure Subscription\n",
    "resource_group = \"fastai-practise\" # Name of a logical resource group\n",
    "workspace_name = \"Azure_projects\" # The name of the workspace to look for or to create\n",
    "workspace_region = 'northcentralus' # Location of the workspace\n",
    "experiment_name = 'cars-classifier'\n",
    "score_script = 'score_and_track.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying KeyVault with name azureprokeyvault5c6672c7.\n",
      "Deploying StorageAccount with name azureprostoragee2191a12f.\n",
      "Deploying AppInsights with name azureproinsightse5dfd4af.\n",
      "Deployed AppInsights with name azureproinsightse5dfd4af. Took 1.86 seconds.\n",
      "Deployed KeyVault with name azureprokeyvault5c6672c7. Took 17.52 seconds.\n",
      "Deploying Workspace with name Azure_projects.\n",
      "Deployed StorageAccount with name azureprostoragee2191a12f. Took 21.38 seconds.\n",
      "Deployed Workspace with name Azure_projects. Took 19.6 seconds.\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.create(name=workspace_name,\n",
    "               subscription_id=subscription_id,\n",
    "               resource_group=resource_group,\n",
    "               create_resource_group=True,\n",
    "               location=workspace_region,\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ws = Workspace.get(name=\"Azure_projects\", subscription_id='d74ca76c-0758-4302-8894-12939776ca14', resource_group='fastai-practise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model cars-classifier\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model = Model.register(model_path=\"export.pkl\",\n",
    "                          model_name=\"cars-classifier\",\n",
    "                          tags={'data': 'cars', 'method':'transfer learning','framework':'pytorch'},\n",
    "                          description='Image classficiation service BMW vs Jagaur vs Mclauren',\n",
    "                          workspace=ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Conda environment specification. The dependencies defined in this file will\r\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\r\n",
      "\n",
      "# Details about the Conda environment file format:\r\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\r\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\r\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\r\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "  - azureml-defaults\n",
      "  - fastai==1.0.60\n",
      "  - pillow==5.4.1\n",
      "  - torch\n",
      "  - torchvision>=0.5.0\n",
      "channels:\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "myenv = CondaDependencies.create(pip_packages=['azureml-defaults', 'fastai==1.0.60','pillow==5.4.1',\n",
    "                                               'torch', 'torchvision>=0.5.0'])\n",
    "\n",
    "with open(\"myenv.yml\",\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "    \n",
    "print(myenv.serialize_to_string())\n",
    "\n",
    "myenv = Environment.from_conda_specification(name=\"myenv\", file_path=\"myenv.yml\")\n",
    "inference_config = InferenceConfig(entry_script=\"score_and_track.py\",\n",
    "                                   environment=myenv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import Webservice\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.exceptions import WebserviceException\n",
    "\n",
    "\n",
    "service_name = 'cars'\n",
    "\n",
    "# Remove any existing service under the same name.\n",
    "try:\n",
    "   Webservice(ws, service_name).delete()\n",
    "except WebserviceException:\n",
    "   pass\n",
    "    \n",
    "aciconfig = AciWebservice.deploy_configuration(cpu_cores=2, \n",
    "                                               memory_gb=4, \n",
    "                                               tags={'data': 'cars',  'method':'transfer learning', 'framework':'pytorch'},\n",
    "                                               description='Image classficiation service BMW vs Jagaur vs Mclauren')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running..............................................................................................................................\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(workspace=ws, \n",
    "                           name=service_name, \n",
    "                           models=[model], \n",
    "                           inference_config=inference_config, \n",
    "                           deployment_config=aciconfig)\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/bin/bash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/bin/bash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n/usr/sbin/nginx: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\n/usr/sbin/nginx: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\\nbash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by bash)\\n2020-03-11T19:51:12,113239861+00:00 - gunicorn/run \\n2020-03-11T19:51:12,114711096+00:00 - rsyslog/run \\n2020-03-11T19:51:12,114794298+00:00 - iot-server/run \\n2020-03-11T19:51:12,116158130+00:00 - nginx/run \\nEdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\\n/bin/bash: /azureml-envs/azureml_1523582bfe50e56e88f1bbf0b060e680/lib/libtinfo.so.5: no version information available (required by /bin/bash)\\n2020-03-11T19:51:12,199041784+00:00 - iot-server/finish 1 0\\n2020-03-11T19:51:12,200285113+00:00 - Exit code 1 is normal. Not restarting iot-server.\\nStarting gunicorn 19.9.0\\nListening at: http://127.0.0.1:31311 (14)\\nUsing worker: sync\\nworker timeout is set to 300\\nBooting worker with pid: 42\\nInitialized PySpark session.\\ngenerated new fontManager\\nInitializing logger\\nStarting up app insights client\\nStarting up request id generator\\nStarting up app insight hooks\\nInvoking user\\'s init function\\n2020-03-11 19:51:15,358 | azureml.core.run | DEBUG | Could not load run context RunEnvironmentException:\\n\\tMessage: Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\\n\\tInnerException None\\n\\tErrorResponse \\n{\\n    \"error\": {\\n        \"message\": \"Could not load a submitted run, if outside of an execution context, use experiment.start_logging to initialize an azureml.core.Run.\"\\n    }\\n}, switching offline: False\\n2020-03-11 19:51:15,358 | azureml.core.run | DEBUG | Could not load the run context and allow_offline set to False\\n2020-03-11 19:51:15,358 | azureml.core.model | DEBUG | version is None. Latest version is 1\\n2020-03-11 19:51:15,358 | azureml.core.model | DEBUG | Found model path at azureml-models/cars-classifier/1/export.pkl\\nUsers\\'s init has completed successfully\\nScoring timeout is found from os.environ: 60000 ms\\n'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service.get_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://0c1b0dc1-f6f1-4ae8-b742-6e9014bec3e8.westus.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "print(service.scoring_uri)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python (Cars_Classfier)",
   "language": "python",
   "name": "cars_classfier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
